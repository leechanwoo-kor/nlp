{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN Classifier - train (tensorflow)의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1w8ew706HC5C"
      },
      "source": [
        "# 트위터 감정 분석\n",
        "\n",
        "이번 실습에서는 트위터 메시지(트윗)의 감정을 분석하는 RNN Classifier를 만들겠습니다.\n",
        "\n",
        "감정에는 긍정, 부정, 중립의 세 가지 레이블이 있습니다.\n",
        "\n",
        "이 정의에 따라 트윗에 담긴 감정을 태깅하였고 이 데이터를 통해 주어진 트윗에 감정을 분석하는 classifier를 만드는 것이 이번 실습에서의 목표입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjj7XEd3BuDy"
      },
      "source": [
        "## 데이터 파일 다운로드\n",
        "\n",
        "데이터 파일을 다운로드 하기 위해 특수 명령어인 gdown을 사용하였습니다.\n",
        "\n",
        "(ipython 형태로 배포될 경우 data 폴더를 만들어 넣겠습니다.)\n",
        "\n",
        "데이터 출처: https://www.kaggle.com/vivekrathi055/sentiment-analysis-on-financial-tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3hwEF6GAiEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb1201e-4517-4bea-8cf0-398327b2f9c9"
      },
      "source": [
        "!gdown --id 1CElFsrPshUPyLIDk0MpkJR01cIcqNdra\n",
        "\n",
        "!gdown --id 1tll145FRmWH8pfnlOCV_mYb3MTLvxf4K\n",
        "\n",
        "!gdown --id 1WJOfcaaW_5nc0Dr573FhX5zFyC5NCp9Z"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1CElFsrPshUPyLIDk0MpkJR01cIcqNdra\n",
            "To: /content/vocab.csv\n",
            "100% 32.3k/32.3k [00:00<00:00, 33.4MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1tll145FRmWH8pfnlOCV_mYb3MTLvxf4K\n",
            "To: /content/valid.csv\n",
            "100% 31.5k/31.5k [00:00<00:00, 46.6MB/s]\n",
            "/usr/local/lib/python3.7/dist-packages/gdown/cli.py:131: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  category=FutureWarning,\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1WJOfcaaW_5nc0Dr573FhX5zFyC5NCp9Z\n",
            "To: /content/train.csv\n",
            "100% 124k/124k [00:00<00:00, 90.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S03tCoPkG6vr"
      },
      "source": [
        "`train.csv` 파일을 열어보면 한 라인에 두 개의 열이 있습니다. \n",
        "\n",
        "첫 번째 열에는 트위터 메시지인 트윗이 있고 오른쪽에는 태깅된 감정이 있습니다.\n",
        "\n",
        "- 0: 부정\n",
        "- 1: 중립\n",
        "- 2: 긍정\n",
        "\n",
        "이렇게 세 가지의 감정이 태깅된 것을 알 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xumuS251GFJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfb364d1-251a-4d52-9b99-d774c4bf7e64"
      },
      "source": [
        "with open(\"train.csv\") as csv_f:\n",
        "    head = \"\\n\".join([next(csv_f) for x in range(5)])\n",
        "print(head)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "critic survey ashford hospit prime ahp amp kimco realti kim,0\n",
            "\n",
            "analyst adopt bullish outlook robert half intern inc rhi,1\n",
            "\n",
            "zack rank strong buy semiconductor stock mlnx intc mchp,2\n",
            "\n",
            "setup like watch wed roku iq sfix shop spot ual goo twlo nflx xrt tsla sq bidu pypl labu biib kss kre,2\n",
            "\n",
            "invesco ivz price target lower credit suiss group,1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvdTJtt1CcRU"
      },
      "source": [
        "## 라이브러리 로드\n",
        "\n",
        "코드 실행에 필요한 라이브러리를 로드합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgnaF87tCfhj"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from IPython.display import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZhhZRkJChKT"
      },
      "source": [
        "## train 함수\n",
        "train 함수는 train 데이터를 통해 모델을 학습하고 valid 데이터로 이를 검증하는 함수입니다.\n",
        "\n",
        "- 문제 1. train 함수 내 model 구성에 있어 마지막에 classification을 위해 dense layer를 추가해주세요. 힌트) class의 개수는 3개입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYucrg5wCjyA"
      },
      "source": [
        "def train(train_dataset, valid_dataset, epochs=20):\n",
        "    # vocab.csv에 적혀진 단어를 기반으로 단어를 벡터로 바꾸는 encoder를 만듭니다.\n",
        "    encoder = tf.keras.layers.experimental.preprocessing.TextVectorization(output_sequence_length=200,\n",
        "                                                                           vocabulary=\"./vocab.csv\")\n",
        "\n",
        "    # RNN classifier 모델을 만듭니다.\n",
        "    # 단어 => encoder => Embedding => 양방향 RNN => Dense => Dense의 구조입니다.\n",
        "    model = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=300, mask_zero=True),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(300)),\n",
        "        tf.keras.layers.Dense(300, activation='relu'),\n",
        "        # <ToDo>: model의 마지막에 classification을 위해 dense layer를 추가해주세요.\n",
        "    ])\n",
        "\n",
        "    # 모델의 loss 함수와 optimizier를 정합니다.\n",
        "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # train 데이터로 학습시키며 valid 데이터로 성능을 확인합니다.\n",
        "    history = model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset, validation_steps=1,\n",
        "                        use_multiprocessing=True, workers=32)\n",
        "\n",
        "    return model, history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjpGUsu0CluV"
      },
      "source": [
        "## test 함수\n",
        "\n",
        "학습된 모델로 테스트 데이터를 이용하여 모델의 성능을 평가합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb-MdzWXCn_F"
      },
      "source": [
        "def test(model, test_dataset):\n",
        "    # test 데이터를 이용하여 모델을 검증합니다.\n",
        "    test_loss, test_acc = model.evaluate(test_dataset)\n",
        "    \n",
        "    # 결과를 출력합니다.\n",
        "    print('Test Loss: {}'.format(test_loss))\n",
        "    print('Test Accuracy: {}'.format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofHYy5NsCpwY"
      },
      "source": [
        "## 그래프 그리는 함수\n",
        "\n",
        "epoch에 따른 train loss와 validation loss 그래프를 그립니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTXXPgoLCpiC"
      },
      "source": [
        "def draw_graph(history, metric='loss'):\n",
        "    plt.plot(history.history[metric])\n",
        "    plt.plot(history.history['val_' + metric], '')\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([metric, 'val_' + metric])\n",
        "    plt.savefig('train_valid_loss.png', bbox_inches='tight')\n",
        "\n",
        "    Image('train_valid_loss.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra8NgFTOCy-p"
      },
      "source": [
        "## 데이터 불러오기\n",
        "\n",
        "- 문제 2. `valid_dataset`을 불러오세요. 힌트) `train_dataset`을 참고하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Jy8JWuPCyvC"
      },
      "source": [
        "# 데이터의 기본 형태에 대한 정보입니다.\n",
        "column_names = [\"text\", \"label\"]\n",
        "column_defaults = [\"string\", \"int32\"]\n",
        "root_path = \"./\"\n",
        "train_file_path = root_path + \"train.csv\"\n",
        "valid_file_path = root_path + \"valid.csv\"\n",
        "\n",
        "# train 데이터 csv 파일을 읽어옵니다.\n",
        "train_dataset = tf.data.experimental.make_csv_dataset(train_file_path, column_names=column_names, batch_size=320,\n",
        "                                                      label_name=\"label\", column_defaults=column_defaults,\n",
        "                                                      header=False, num_epochs=1)\n",
        "\n",
        "# <ToDo>: valid_dataset을 불러오세요.\n",
        "valid_dataset = None # Problem 2\n",
        "\n",
        "# <ToDo>: valid_dataset과 test_dataset을 불러오세요.\n",
        "train_dataset = train_dataset.map(lambda text, label: (text[\"text\"], label))\n",
        "valid_dataset = None # Problem 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNlcKZKoDDEq"
      },
      "source": [
        "## 모델 학습\n",
        "\n",
        "- 문제 3. `train` 함수를 이용하여 train data를 통해 모델 학습을 진행하세요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpjT1fyTDF15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "4dd3f4b6-9537-4e23-e451-824e6c58b536"
      },
      "source": [
        "# <ToDo>: 학습을 위해 train 함수의 적절한 parameter를 전달해주세요.\n",
        "model, history = train(None)  # Problem 3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-ff3ef4fb8f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# <ToDo>: 학습을 위해 train 함수의 적절한 parameter를 전달해주세요.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Problem 3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: train() missing 1 required positional argument: 'valid_dataset'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-wJEf05DJ8Q"
      },
      "source": [
        "## 그래프 출력"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFiSShyMDLOX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "outputId": "35f98f3c-8bc2-4619-9e68-8671a283d91b"
      },
      "source": [
        "# 학습 히스토리를 통해 training loss와 validation loss를 그래프로 그립니다.\n",
        "draw_graph(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-bbb2e91220e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 히스토리를 통해 training loss와 validation loss를 그래프로 그립니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdraw_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cneFmMidXZ5o"
      },
      "source": [
        "## 추가 질문\n",
        "\n",
        "위의 그림을 보면서 최적의 Epoch 개수를 찾아보세요.\n",
        "\n"
      ]
    }
  ]
}